[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Modal Logic",
    "section": "",
    "text": "Preface\nThis is a textbook for PHIL 452: Modal Logic.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "Propositional logic classifies propositions into main categories: true and false. Alethic modal logic makes distinctions between different modes in which a proposition may be true or false. The formal framework of modal logic expands the language of propositional logic with a sentential operator, \\(\\Box\\), for one of those modes, necessity, and a dual operator, \\(\\Diamond\\), for another, possibility. There are, however, other interpretations of the formalism.\nThese distinctions may play a crucial role in philosophical argumentation.\nHow should we interpret the formalism? We use truth tables to interpret the language of propositional logic because propositional connectives are truth-functional, e.g., the truth value of a conjunction is a function of the truth values of its conjuncts. The strategy does not seem to be available in the case of modal logic, since the modal operator \\(\\Box\\) is not truth-functional:\n\\[\n\\begin{array}{|c|c|}\n\\hline\n\\varphi & \\Box \\varphi \\\\\n\\hline\nT  & ? \\\\\n\\hline\nF  &  F \\\\\n\\hline\n\\end{array}\n\\]\nWhen \\(\\varphi\\) is false, \\(\\Box \\varphi\\) will of course be false. But the truth of \\(\\varphi\\) leaves open whether \\(\\Box \\varphi\\) is true or false, e.g., \\(\\Box \\varphi\\) will be true when \\(\\varphi\\) is a tautology but false when \\(\\varphi\\) is interpreted to make a contingent statement.\nOne may attempt to overcome this limitation with the help of a more fine-grained distinction between necessary and contingent truths, on the one hand, and necessary and contingent falsehoods, on the other. We may even reserve the letters \\(t\\) and \\(T\\) for contingent and necessary truths respectively, and we may similarly use \\(f\\) and \\(F\\) for contingent and necessary falsehoods respectively. This appears to suggests a truth table for each negation and \\(\\Box\\):\n\\[\n\\begin{array}{|c|c|c|}\n\\hline\n\\varphi & \\neg \\varphi & \\Box \\varphi\\\\\n\\hline\nT  & F & T\\\\\n\\hline\nt  &  f & F\\\\\n\\hline\nF  & T & F\\\\\n\\hline\nf  &  t & F\\\\\n\\hline\n\\end{array}\n\\]\nThe problem remains that we cannot generalize the scheme to cover binary propositional connectives such as the material connective. Once we opt for the more fine-grained distinction between necessary and contingent truths and falsehoods, the truth value of the conditional ceases to be a function of the truth values of antecedent and consequent.\n\\[\n\\begin{array}{|c|c|c|c|c|}\n\\hline\n\\to & T & t & F & f\\\\\n\\hline\nT  & T & t & F  &  f \\\\\n\\hline\nt  &  T & ? & F &  f\\\\\n\\hline\nF  & T & T & T & T \\\\\n\\hline\nf  &  T & t & t & ? \\\\\n\\hline\n\\end{array}\n\\]\nWhen \\(\\varphi\\) and \\(\\psi\\) are contingently true, \\(\\varphi \\to \\psi\\) may be necessarily true, e.g., \\(p \\to p\\) if \\(p\\) is contingently true, or merely contingently true, e.g., \\(p\\to q\\) for suitable choices of contingent propositions \\(p\\) and \\(q\\). Likewise, when \\(\\varphi\\) and \\(\\psi\\) are contingently false, the conditional may be necessarily or contingently true.\nWe must look elsewhere for an interpretation of the formalism of propositional modal logic. One key observation at this point is that propositions differ not just with respect to whether they are true or false, they may differ with respect to the circumstances under which they are true or false. The propositions expressed by the statements ‘Los Angeles has over three million inhabitants’ and ‘Kilimanjaro rises to 5,895 meters’ are both true but there are possible circumstances under which one is true and the other is false.\nWe may think of possible worlds as complete specifications of a way the world might be, and we may ask whether a sentence is true at a possible world. That is, we may ask whether the possible world in question specifies circumstances under which the sentence is in fact true.\nOnce we take on board the thought that a sentence may be true when evaluated with respect to one possible world but not when evaluated with respect to another, we may ask what is for a possible world to be possible relative to another. The proposition that I’m a philosopher is true given how the world is, but there are possible circumstances under which I’m an engineer. We codify that as the thought that a world at which I’m an engineer is possible with respect to the world of evaluation. We will call a possible world is accessible from another world if the former is possible with respect to the latter.\nWe now have the basic ingredients for a possible world semantics for propositional modal logic. More formally, a model for the framework will consist of a collection of possible worlds \\(W\\), an accessibility relation \\(R\\) on the collection \\(W\\), and a valuation function, which specifies which propositions are true at what possible worlds.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#footnotes",
    "href": "intro.html#footnotes",
    "title": "1  Introduction",
    "section": "",
    "text": "Please do not worry if any of those terms are new to you. Much of what we will do before we formally introduce the language of propositional modal logic is to cover some preliminaries, which will include some discussion of the structure of binary relations.↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "background.html",
    "href": "background.html",
    "title": "2  Background",
    "section": "",
    "text": "2.1 Sets\nA set is a collection of elements.\nOne may think that no mater what objects may be, there is a collection of them. Or, otherwise put, for each condition \\(\\dots x \\dots\\), there is a collection of all and only those objects satisfying the condition \\(\\dots x \\dots\\). That is, there is a set of the form \\(\\{x: \\dots x \\dots\\}\\). But that would be a mistake.\nIn response to Russell’s paradox, we limit ourselves to collections we may construct from given collections in accordance to the axioms of modern set theory.\nThe axiom of separation yields the existence of sets conditional on the existence of supersets. To secure the inconditional existence of a set, we require another axiom.\nOther axioms help us justify the existence of further sets:",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Background</span>"
    ]
  },
  {
    "objectID": "background.html#sets",
    "href": "background.html#sets",
    "title": "2  Background",
    "section": "",
    "text": "Notation\n\n\n\nWe will generally use uppercase letters as labels for sets and lowercase letters as labels for their elements. We write \\(a \\in A\\) to indicate that \\(a\\) is an element of \\(A\\).\nWe may specify a set by enumeration, e.g., \\(\\{0, 2, 4\\}\\) is a set of three natural numbers. Alternatively, we may specify the same set by the specification of a condition satisfied by all, and only its elements, e.g., {\\(x\\): \\(x\\) is an even natural number less than 5}\n\n\n\nDefinition 2.1 A set \\(A\\) is a subset of another set \\(B\\), written \\(A \\subseteq B\\), if every element of \\(A\\) is an element of \\(B\\). A set \\(A\\) is a proper subset of \\(B\\) if \\(A\\) is a subset of \\(B\\) but \\(B\\) is not a subset of \\(A\\).\n\n\nProposition 2.1 (Extensionality) If \\(A\\) is a subset of \\(B\\) and \\(B\\) is a subset of \\(A\\), then \\(A\\) is the same set as \\(B\\). That is, \\(A = B\\).\n\n\n\n\n\n\n\nExample\n\n\n\nThe singleton {6} is the same set as {\\(x\\): \\(x\\) is a perfect number less than 10}. A perfect number is the sum of its proper divisors, e.g, 6 is perfect because it is a sum of 1, 2, and 3.\nOn the one hand, {6) \\(\\subseteq\\) {\\(x\\): \\(x\\) is a perfect number less than 10}, since 6 is a perfect number less than 10.\nOn the other hand, {\\(x\\): \\(x\\) is a perfect number less than 10} \\(\\subseteq\\) {6}, since nothing else is a perfect number less than 10.\nBy Extensionality, {6} = {\\(x\\): \\(x\\) is a perfect number less than 10}.\n\n\n\n\n\n\n\n\n\nRussell’s paradox\n\n\n\nConsider the condition \\(x \\notin x\\). There is no set of the form \\(\\{x : x \\notin x\\}\\). For suppose such a set exists, which we may call \\(R\\).\n\nif \\(R \\in R\\), then \\(R\\) fails to satisfy the condition \\(x \\notin x\\), which means that \\(R\\notin R\\).\nif \\(R\\notin R\\), then \\(R\\) satisfies the condition \\(x \\notin x\\), which means that \\(R \\in R\\).\n\nWe conclude that \\(R \\in R\\) if, and only if, \\(R \\notin R\\), which leads to contradiction.\n\n\n\n\nProposition 2.2 (Separation) If \\(A\\) is a set and \\(\\dots x \\dots\\) is a condition on elements of \\(A\\), then there is a set \\(B\\) of exactly those elements of \\(A\\) which satisfy the condition \\(\\dots x \\dots\\). That is, \\(B = \\{x \\in A: \\dots x \\dots\\}\\)\n\n\n\nProposition 2.3 (Empty Set) There is a set without members which we label \\(\\emptyset\\). That is, \\(\\emptyset\\) is the set \\(\\{x: x \\neq x\\}\\).\n\n\n\nProposition 2.4 (Pair Set) Given two objects \\(a\\) and \\(b\\), there is a set whose elements are exactly \\(a\\) and \\(b\\). We write \\(\\{a, b\\}\\) for the pair set of \\(a\\) and \\(b\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Background</span>"
    ]
  },
  {
    "objectID": "background.html#relations",
    "href": "background.html#relations",
    "title": "2  Background",
    "section": "2.2 Relations",
    "text": "2.2 Relations\nWe construe relations as sets of ordered pairs. But an ordered pair is itself a special set from which we can recover the order in which two components are given.\n\nDefinition 2.2 (Ordered Pair) The ordered pair of \\(a\\) and \\(b\\), \\((a, b)\\), is a doubleton set \\(\\{\\{a\\},\\{a, b\\}\\}\\). We will write that its first element is \\(a\\) and that its second element is \\(b\\).\n\nOther definitions of ordered pair are feasible, but what matters is the ability to encode the order in which the two components are given.\n\nTheorem 2.1 The ordered pair \\((a, b)\\) is the same as the ordered pair \\((c, d)\\) if, and only if, \\(a\\) is the same object as \\(c\\) and \\(b\\) is the same object as \\(d\\).\n\n\nWe first unfold the definition of \\((a, b)\\) as \\(\\{\\{a\\}, \\{a, b\\}\\}\\) and \\((c, d)\\) as \\(\\{\\{c\\},\\{c, d\\}\\}\\). We now argue that if \\(\\{\\{a\\},\\{a, b\\}\\}\\) is the same set as \\(\\{\\{c\\},\\{c, d\\}\\}\\), then \\(a=c\\) and \\(b = d\\).\nWe distinguish two cases:\n\nIf \\(a=b\\), then \\(\\{\\{a\\},\\{a, b\\}\\}\\) is \\(\\{\\{a\\},\\{a,a\\}\\}\\), which is just \\(\\{a\\}\\}\\). So, if \\(\\{\\{a\\},\\{a, b\\}\\}\\) is the same set as \\(\\{\\{c\\},\\{c, d\\}\\}\\), then \\(\\{\\{a\\}\\}\\) is the same set as \\(\\{\\{c\\},\\{c, d\\}\\}\\), which means that \\(c = d\\) and \\(a= c\\) and \\(b = d\\).\nIf \\(a\\neq b\\), then the singleton \\(\\{a\\}\\) and the doubleton \\(\\{a, b\\}\\) must correspond to \\(\\{c\\}\\) and \\(\\{c, d\\}\\), respectively, which requires that \\(a=c\\) and \\(b=d\\).\n\n\nWe can now identify a relation with a set of ordered pairs.\n\nDefinition 2.3 (Cartesian Product) The Cartesian Product \\(A \\times B\\) of two sets \\(A\\) and \\(B\\) is the set of ordered pairs whose first element belongs to \\(A\\) and whose second element belongs to \\(B\\). That is, the Cartesian Product of two sets \\(A\\) and \\(B\\) is:\\[\nA \\times B = \\{(x, y): x\\in A \\wedge y\\in B\\}.\n\\]\n\n\nDefinition 2.4 (Relation) If \\(A\\) is a set, \\(R\\) is a binary relation on \\(A\\) if, and only if, \\(R\\) is a subset of \\(A \\times A\\).\n\n\n\n\n\n\n\nNotation\n\n\n\nIf \\(R\\) is a relation on \\(A\\), we sometimes write \\(Rxy\\) or \\(xRy\\) for \\((x, y) \\in R\\).\n\n\n\n2.2.1 Structural Features of Relations\nWe now specify a variety of structural features a relation may exemplify.\n\nDefinition 2.5 If \\(R\\) is a binary relation on a set \\(A\\),\n\n\\(R\\) is reflexive on \\(A\\) iff for every element \\(x \\in  A\\), \\(Rxx\\)\n\\(R\\) is irreflexive on \\(A\\) iff for every element \\(x \\in  A\\), \\(\\neg Rxx\\) for every element \\(x\\) in \\(A\\).\n\\(R\\) is non-reflexive on \\(A\\) iff for some element \\(x \\in  A\\), \\(\\neg Rxx\\).\n\n\n\n\n\n\n\n\nExample\n\n\n\nConsider the set of English words \\(W\\). Then:\n\n{\\((u,v)\\in W \\times W\\): \\(u\\) shares at least one letter with \\(v\\)} is a reflexive relation on \\(W\\).\n{\\((u,v)\\in W \\times W\\): \\(u\\) is an antonym of \\(v\\)} is an irreflexive relation on \\(W\\).\n{\\((u,v)\\in W \\times W\\): \\(u\\) is \\(v\\) backwards} is a non-reflexive relation on \\(W\\).1\n\n\n\n\nDefinition 2.6 (Symmetry) If \\(R\\) is a binary relation on a set \\(A\\),\n\n\\(R\\) is symmetric on \\(A\\) iff for all \\(x, y \\in A\\), if \\(Rxy\\), then \\(Ryx\\).\n\\(R\\) is asymmetric on \\(A\\) iff for all \\(x,y \\in A\\), if \\(Rxy\\), then \\(\\neg Ryx\\).\n\\(R\\) is non-symmetric on \\(A\\) iff for some \\(x, y \\in A\\), \\(Rxy\\) and \\(\\neg Ryx\\).\n\\(R\\) is antisymmetric on \\(A\\) iff for all \\(x, y \\in A\\), if \\(Rxy\\), then \\(Ryx\\) only if \\(x=y\\)\n\n\n\n\n\n\n\n\nExample\n\n\n\nConsider the set of English words \\(W\\). Then:\n\n{\\((u,v)\\in W \\times W\\): \\(u\\) shares at least one letter with \\(v\\)} is a symmetric relation on \\(W\\).\n{\\((u,v)\\in W \\times W\\): \\(u\\) has fewer letters than \\(v\\)} is an asymmetric relation on \\(W\\).\n{\\((u,v)\\in W \\times W\\): \\(u\\) is no later than \\(v\\) in the lexicographical order} is an anti-symmetric relation on \\(W\\).\n\n\n\n\nDefinition 2.7 (Transitivity) If \\(R\\) is a binary relation on a set \\(A\\),\n\n\\(R\\) is transitive on \\(A\\) iff for all elements \\(x,y,z \\in A\\), if \\(Rxy\\) and \\(Ryz\\), then \\(Rxz\\).\n\\(R\\) is intransitive on \\(A\\) iff for all elements \\(x,y,z \\in A\\), if \\(Rxy\\) and \\(Ryz\\), then \\(\\neg  Rxz\\).\n\\(R\\) is non-transitive on \\(A\\) iff for some elements \\(x,y,z \\in A\\), if \\(Rxy\\) and \\(Ryz\\), then \\(\\neg  Rxz\\).\n\n\n\n\n\n\n\n\nExample\n\n\n\nConsider the set of English words \\(W\\). Then:\n\n{\\((u,v)\\in W \\times W\\): \\(u\\) is no later than \\(v\\) in the lexicographical order} is a transitive relation on \\(W\\).\n{\\((u,v)\\in W \\times W\\): \\(u\\)  is an antonym of \\(v\\)} is an intransitive relation on \\(W\\).\n{\\((u,v)\\in W \\times W\\): \\(u\\) is \\(v\\) backwards} is a non-transitive relation on \\(W\\).2\n\n\n\n\nDefinition 2.8 (Equivalence Relation) A binary relation \\(R\\) on a set \\(A\\) is an equivalence relation on \\(A\\) if, and only if,\n\n\\(R\\) is reflexive on \\(A\\), and\n\\(R\\) is symmetric on \\(A\\), and\n\\(R\\) is transitive on \\(A\\).\n\n\n\n\n\n\n\n\nExample\n\n\n\nSynonymy is an equivalence relation on the set of English words \\(W\\).\n\nSynonymy is reflexive on \\(W\\).\nEvery word is a synonym of itself.\nSynonymy is symmetric on \\(W\\).\nIf a word is a synonym of another word, then the latter word is a synonym of the former.\nSynonymy is transitive on \\(W\\).\nIf a word is a synonym of a second word and the second word is a synonym of a third, then the first word is a synonym of the third word.\n\n\n\nGiven an equivalence relation \\(R\\) on a set \\(A\\), we will write that two elements \\(x, y \\in A\\) are \\(R\\)-equivalent when \\(Rxy\\). Equivalence relations induce a partition of the relevant set \\(A\\) into equivalence classes.\n\nDefinition 2.9 (Equivalence Class) If a relation \\(R\\) is an equivalence relation on a set \\(A\\), for each \\(x\\in A\\), the equivalence class of \\(x\\), written \\([x]_R\\) is the set of elements of \\(A\\) that are \\(R\\)-equivalent to it: \\[\n  [x]_R:=\\{y\\in A: Rxy\\}.\n  \\] The quotient of \\(A\\) under \\(R\\) is the set of equivalence classes induced by \\(A\\): \\[\n  A/R:= \\{[x]_R: x \\in A\\}.\n  \\]\n\n\n\n\n\n\n\nExample\n\n\n\nGiven a set \\(A\\) of undergraduate students enrolled at USC, consider the following binary relation \\(R\\) on \\(A\\):\n\n\\(R = \\{(x,y)\\in A\\times A: x\\)  is in the same year as  \\(y\\}\\).\n\n\\(R\\) is an equivalence relation on \\(A\\).\nGiven a student \\(a\\), the equivalence class \\([a]_R\\) is the set of students in the same year as \\(a\\). If \\(a\\) is a freshman, then \\([a]_R\\) will be the set of freshman students, if \\(a\\) is a sophomore, then \\([a]_R\\) will be the set of sophomore students, etc.\nThe quotient of \\(A\\) under \\(R\\), \\(A/R\\), consists of four sets: freshman, sophomore, junior, and senior students.\n\n\nThere is an alternative characterization of equivalence relations in terms of reflexivity and yet another structural feature of relations.\n\nDefinition 2.10 (Euclidean) If \\(R\\) is a binary relation on a set \\(A\\), then:\n\n\\(R\\) is euclidean on \\(A\\) iff for all elements \\(x, y, z\\in A\\), if if \\(Rxy\\) and \\(Rxz\\), then \\(Ryz\\).\n\n\nHere is the alternative characterization of an equivalence relation in question:\n\nTheorem 2.2 If \\(R\\) is a binary relation on a set \\(A\\), then \\(R\\) is an equivalence relation on \\(A\\) if, and only if, \\(R\\) is reflexive on \\(A\\) and \\(R\\) is euclidean on \\(A\\).\n\n\n\n\n\n\n\nFurther Structural Features of Relations\n\n\n\nIf \\(R\\) is a binary relation on a set \\(A\\), then:\n\n\\(R\\) is serial on \\(A\\) iff for every \\(x\\in A\\), there is some \\(y\\in A\\) such that \\(Rxy\\).\n\\(R\\) is convergent on \\(A\\) iff for every \\(x,y,z\\in A\\), if \\(Rxy\\) and \\(Rxz\\), then for some \\(w\\in A\\), \\(Ryw\\) and \\(Rzw\\).\n\\(R\\) is connected on \\(A\\) iff for every \\(x, y, z\\in A\\), if \\(Rxy\\) and \\(Rxz\\), then \\(Ryz\\) or \\(Rzy\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Background</span>"
    ]
  },
  {
    "objectID": "background.html#mathematical-induction",
    "href": "background.html#mathematical-induction",
    "title": "2  Background",
    "section": "2.3 Mathematical Induction",
    "text": "2.3 Mathematical Induction\nInduction is a powerful method of proof. We will be able to establish a variety of generalizations over items ordered by the natural numbers, e.g., formulas and proofs by induction of length. Because natural numbers are defined inductively from \\(0\\) and the successor operation, they are similarly governed by a principle of induction:\n\nProposition 2.5 (Induction on the Natural Numbers) Given a condition \\(\\Phi(x)\\) on natural numbers, if\n\n\\(0\\) satisfies \\(\\Phi(x)\\), and\na natural number \\(n\\) satisfies \\(\\Phi(x)\\) only if its successor, \\(n+1\\), satisfies \\(\\Phi(x)\\),\n\nthen every natural number satisfies \\(\\Phi(x)\\).\n\n\n\n\n\n\n\nExample\n\n\n\nconsider the pattern below: \\[\n\\begin{array}{llll}\n1 & = & 1 & = & \\frac{1 .(1+1)}{2}\\\\\n1+2 & = & 3 & = & \\frac{2 . (2+1)}{2}\\\\\n1 + 2+ 3 & = & 6 & = & \\frac{3 . (3+1)}{2}\\\\\n\\cdots & = & \\cdots & = & \\cdots \\\\\n\\end{array}\n\\]Carl Gauss exploited when he noticed that the sum of the first \\(100\\) positive integers is \\(5050\\), which is \\(\\frac{100.(100 +1)}{2}\\) when asked by his teacher. It turns out the pattern is completely general.\nWe use an induction on the positive integers to prove the generalization:\n\nFor every positive integer \\(n\\), \\[\n\\sum_{k = 1}^{n} = \\frac{n.(n+1)}{2}.\n\\]\n\nHere the condition \\(\\Phi(n)\\) is: \\[\n\\sum_{k = 1}^{n} = \\frac{n.(n+1)}{2}\n\\]\nBy induction on the positive integers, it suffices to show:\n\n\\(\\Phi(1)\\) , and \\[\n\\sum_{n = 1}^{1} = \\frac{1.(1+1)}{2}\n\\]\n\\(\\Phi(n)\\) only if \\(\\Phi(n+1)\\).\nThat is, suppose:\n\n\\[\n\\sum_{k=1}^{n} = \\frac{n.(n+1)}{2}.\n\\]\nThen:\n\\[\n\\begin{array}{lll}\n\\sum_{k=1}^{n+1} & = & \\sum_{k=1}^{n} + (n+1)\\\\  & =  & \\frac{n.(n+1)}{2} + (n+1)\\\\\n& = & \\frac{n^2 + 3n +2}{2} \\\\\n& = &\\frac{(n+1).((n+1)+1)}{2}  \\\\\n\\end{array}\n\\]So, we conclude that every positive integer \\(n\\) satisfies the condition.\n\n\nA word of caution. Mathematical induction becomes all too powerful when it is misused. Here is an example of how a misapplication of mathematical induction can lead us astray. In the case at hand, we misuse induction to argue for the absurd claim that all finite sets have the same cardinality.\n\n\n\n\n\n\nHow Not to Use Induction\n\n\n\nLet \\(\\Phi(x)\\) be the following condition on natural numbers:\n\nno two sets with fewer than \\(n\\) elements differ in cardinality.\n\nWe (mis)use induction to argue that the condition holds for every natural number. We proceed in two steps:\n\n\\(\\Phi(0)\\).\nSuppose two sets \\(A\\) and \\(B\\) have at most \\(0\\) elements. Then. \\(A =\\emptyset =B\\).\nwhenever \\(\\Phi(n)\\), we have \\(\\Phi(n+1)\\).\n\nSuppose \\(\\Phi(n)\\) and let now \\(A\\) and \\(B\\) be two sets with at most \\(n+1\\) elements. Now, consider the sets \\(A^-\\) and \\(B^-\\), which result from \\(A\\) and \\(B\\), respectively, when we substract one element \\(a\\) and \\(b\\) from each. By inductive hypothesis, since \\(A^-\\) and \\(B^-\\) have at most \\(n\\) elements, they have the same cardinality. But if they do, so will \\(A^- \\cup \\{a\\}\\) and \\(B^- \\cup \\{b\\}\\), which are none other than \\(A\\) and \\(B\\).\nThe conclusion of the argument is that no two finite sets differ in cardinality, which is patently false. Where exactly is the flaw in the argument?\n\n\nWe will sometimes rely on alternative but equivalent forms of induction:\n\nProposition 2.6 (Complete Induction) Given a condition \\(\\Phi(x)\\) on natural numbers, if\n\n\\(0\\) satisfies \\(\\Phi(x)\\), and\nwhenever all natural numbers \\(m\\) less or equal to \\(n\\) satisfy \\(\\Phi(x)\\), the successor \\(n+1\\) satisfies \\(\\Phi(x)\\),\n\nthen all natural numbers satisfy \\(\\Phi(x)\\).\n\nEquivalently:\n\nProposition 2.7 (Complete Induction without a Base Case) Given a condition \\(\\Phi(x)\\) on natural numbers, if\n\nwhenever all natural numbers \\(m\\) less than \\(n\\) satisfy \\(\\Phi(x)\\), \\(n\\) satisfies \\(\\Phi(x)\\),\n\nthen all natural numbers satisfy \\(\\Phi(x)\\).\n\nNotice that \\(\\Phi(0)\\) will be true if the conditional above holds, for it will be vacuously true that all natural numbers less than \\(0\\) satisfy the condition \\(\\Phi\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Background</span>"
    ]
  },
  {
    "objectID": "background.html#footnotes",
    "href": "background.html#footnotes",
    "title": "2  Background",
    "section": "",
    "text": "Consider the word ‘radar’ for example.↩︎\nConsider the words ‘flow’ and ‘wolf’, for example.↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Background</span>"
    ]
  },
  {
    "objectID": "propositional.html",
    "href": "propositional.html",
    "title": "3  Basic Propositional Language",
    "section": "",
    "text": "3.1 Syntax\nWe introduce the syntax and semantics of a basic propositional language with an eye to the study of its metatheory. We will for example prove that propositional validity aligns with provability in an axiomatic deductive system for propositional logic.\nWe first specify the syntax of a propositional language:\nThat is, a string of symbols is a formula if, and only if, it arises from atoms from negation or the conditional in a finite number of steps.\nThe use of \\(\\neg\\) and \\(\\to\\) as basic connectives is a departure from common presentations of the language, which generally include \\(\\wedge\\), \\(\\vee\\), and \\(\\bot\\). These connectives will be defined in terms of \\(\\neg\\) and \\(\\to\\).\nWe now define familiar connectives in terms of \\(\\neg\\) and \\(\\to\\):\nThe inductive definition of well-formed formula vindicates a principle of induction for well-formed formulas, which will help us prove different generalizations over them.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Basic Propositional Language</span>"
    ]
  },
  {
    "objectID": "propositional.html#syntax",
    "href": "propositional.html#syntax",
    "title": "3  Basic Propositional Language",
    "section": "",
    "text": "Basic Propositional Language\n\n\n\nWe chose a stock of propositional variables or atoms:\n\\[\nAT := p, q, r, \\cdots\n\\]\nWe define the formulas of a propositional language \\(\\mathcal{L}\\) recursively:\n\\[\n\\varphi ::= AT \\ | \\ \\neg \\varphi \\ | \\ (\\varphi \\to \\psi)\n\\]\nHere is how to read the last line:\n\nAll atoms are formulas.\nIf \\(\\varphi\\) is a formula, then \\(\\neg \\varphi\\) is a formula.\nIf \\(\\varphi\\) and \\(\\psi\\) are formulas, then \\((\\varphi \\to \\psi)\\) is a formula.\n\n\n\n\n\n\n\nDefinition 3.1 (Connectives) \\[\n\\begin{array}{lll}\n\\top & := & (p \\to p)\\\\\n\\bot & := & \\neg \\top \\\\\n(\\varphi \\vee \\psi) & := & (\\neg \\varphi \\to \\psi)\\\\\n(\\varphi \\wedge \\psi) & := & \\neg (\\varphi \\to \\neg \\psi)\\\\\n(\\varphi \\leftrightarrow \\psi) & := & (\\varphi \\to \\psi) \\wedge (\\psi \\to \\varphi)\n\\end{array}\n\\]\n\n\n\n\n\n\n\n\nInduction on the Complexity of Formulas\n\n\n\nGiven a condition \\(\\Phi(\\alpha)\\) on formulas of \\(\\mathcal{L}\\), if\n\nall atoms satisfies \\(\\Phi(\\alpha)\\),\nwhenever a formula \\(\\varphi\\) satisfies \\(\\Phi(\\alpha)\\), \\(\\neg \\varphi\\) satisfies \\(\\Phi(\\alpha)\\), and\nwhenever two formulas \\(\\varphi\\) and \\(\\psi\\) satisfy \\(\\Phi(\\alpha)\\), \\((\\varphi \\to \\psi)\\) satisfies \\(\\Phi(\\alpha)\\),\n\nthen every formula satisfies \\(\\Phi(\\alpha)\\)\n\n\n\n\n\n\n\n\nExample\n\n\n\nCall a formula \\(\\varphi\\) balanced iff \\(\\varphi\\) contains the same number of left and right parentheses. We will use an induction to establish the proposition:\n\nEvery formula is balanced.\n\nWe use an induction on the complexity of formulas.\n\nBase Case. An atom, e.g., \\(p\\), contains an equal number of left and right parentheses, namely, zero.\nInductive Step for \\(\\neg\\). Whenever a formula \\(\\varphi\\) is balanced, its negation \\(\\neg \\varphi\\) is similarly balanced.\nLet \\(\\varphi\\) be a balanced formula. Since \\(\\neg \\varphi\\) contains exactly as many left and right parentheses as \\(\\varphi\\), it still contains an equal number of left and right parentheses. So, \\(\\neg \\varphi\\) is balanced.\nInductive Step for \\(\\to\\). Whenever formula \\(\\varphi\\) and a formula \\(\\psi\\) are balanced, the conditional \\((\\varphi \\to \\psi)\\) is balanced as well.\nLet \\(\\varphi\\) and \\(\\psi\\) be two balanced formulas and let \\(n\\) and \\(m\\) be the number of left and right parentheses each formula has. \\((\\varphi \\to \\psi)\\) contains \\(n+m +1\\) left parentheses, that is the number of left parentheses in \\(\\varphi\\) plus that of left parentheses in \\(\\psi\\) plus the initial left parenthesis of the formula. \\((\\varphi \\to \\psi)\\) similarly contains \\(n+m +1\\) right parentheses, that is the number of right parentheses in \\(\\varphi\\) plus that of right parentheses in \\(\\psi\\) plus the final right parenthesis of the formula. So, \\((\\varphi \\to \\psi)\\) contains exactly the same number of left and right parentheses, which means that it will be a balanced formula.\n\nWe conclude that every formula is balanced.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Basic Propositional Language</span>"
    ]
  },
  {
    "objectID": "propositional.html#semantics",
    "href": "propositional.html#semantics",
    "title": "3  Basic Propositional Language",
    "section": "3.2 Semantics",
    "text": "3.2 Semantics\nThe role of a semantics for propositional logic is to explain how to interpret the formal language in order to provide fruitful definitions of validity and logical consequence. We do this by means of assignments of truth values to atomic formulas of the language.\n\n\n\n\n\n\nAssignment\n\n\n\nAn assignment for a propositional language \\(\\mathcal{L}\\) is a function \\(v\\) from \\(AT\\) into \\(\\{0, 1\\}\\), which maps a propositional variable to a truth value.\n\n\n\n\n\n\n\n\nValuation\n\n\n\nA valuation \\(V\\) based on an assignment \\(v\\) is a function of the form:\n\\[\n\\begin{array}{lll}\nV(p) & = & v(p)\\\\\n& & \\\\\nV(\\neg \\varphi) & = & \\begin{cases}1 \\ \\ \\ \\text{if} \\ V(\\varphi) =0\\\\ 0 \\ \\ \\ \\text{if} \\ V(\\varphi) = 1 \\end{cases}\\\\\n& & \\\\\nV(\\varphi \\to \\psi) & = & \\begin{cases}1 \\ \\ \\ \\text{if} \\ V(\\varphi) =0 \\ \\text{or} \\ V(\\psi) = 1\\\\ 0 \\ \\ \\ \\text{if} \\ V(\\varphi) = 1 \\ \\text{and} \\ V(\\psi) = 0\\end{cases}\\\\\n\\end{array}\n\\]\n\n\n\n\n\n\n\n\nSatisfaction\n\n\n\nA valuation \\(V\\) satisfies a formula \\(\\varphi\\) if, and only if, \\(V(\\varphi) = 1\\).\nA set of formulas \\(\\Gamma\\) is satisfiable if, and only if, some valuation \\(V\\) satisfies every element of \\(\\Gamma\\).\n\n\n\n\n\n\n\n\nNotation\n\n\n\nWe write that a formula \\(\\varphi\\) is satisfiable as shorthand for the claim that \\(\\{\\varphi\\}\\) is satisfiable.\nWe write that a set \\(\\Gamma\\) is unsatisfiable if \\(\\Gamma\\) is not satisfiable.\n\n\n\n\n\n\n\n\nValidity\n\n\n\nA formula \\(\\varphi\\) is propositionally valid, \\(\\models \\varphi\\), if, and only if, every valuation satisfies \\(\\varphi\\).\nIf \\(\\Gamma\\) is a set of formulas, a formula \\(\\varphi\\) is a logical consequence of \\(\\Gamma\\), \\(\\Gamma \\models \\varphi\\), if, and only if, every valuation satisfying every element of \\(\\Gamma\\) satisfies \\(\\varphi\\).\n\n\n\n\n\n\n\n\nExercise\n\n\n\nTrue or false?\n\nA formula \\(\\varphi\\) is unsatisfiable if, and only if, \\(\\neg \\varphi\\) is valid.\nA conjunction \\(\\varphi \\wedge \\psi\\) is unsatisfiable if, and only if, \\(\\neg \\varphi\\) is valid or \\(\\neg \\psi\\) is valid.\n\\(\\Gamma \\models \\varphi\\) if, and only if, \\(\\Gamma \\cup \\{\\varphi\\}\\) is satisfiable.\n\\(\\Gamma \\models \\varphi\\) if, and only if, \\(\\Gamma \\cup \\{\\neg \\varphi\\}\\) is unsatisfiable.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Basic Propositional Language</span>"
    ]
  },
  {
    "objectID": "propositional.html#axiomatic-derivations",
    "href": "propositional.html#axiomatic-derivations",
    "title": "3  Basic Propositional Language",
    "section": "3.3 Axiomatic Derivations",
    "text": "3.3 Axiomatic Derivations\nWe now present an axiom system for propositional logic, which will consist of an infinite set of axioms and a single rule of inference. A derivation of a well-formed formula from a set of formulas will consist of a finite sequence of formulas each of whose members will either be an axiom or a premise or the output of an application of the rule of inference to prior members of the sequence.\nThere is one ingredient we will use for the specification of the infinite set of axioms. If \\(\\varphi\\) is a propositional formula whose propositional variables are \\(p_1, ..., p_n\\) and \\(\\psi_1\\), …, \\(\\psi_n\\) are propositional formulas, we write \\[\n\\varphi[\\psi_1/p_1, ..., \\psi_n/p_n]\n\\]\nfor the well-formed formula that results from \\(\\varphi\\) when each propositional variable \\(p_i\\) is substituted for the well-formed formula \\(\\psi_i\\). We will call \\(\\varphi[\\psi_1/p_1, ..., \\psi_n/p_n]\\) a substitution instance of \\(\\varphi\\).\n\n\n\n\n\n\nUniform Substitution\n\n\n\nGiven a well-formed formula \\(\\varphi\\) whose propositional variables are among \\(p_1, \\dots, p_n\\) and well-formed formulas \\(\\psi_1, \\dots, \\psi_n\\), define \\(\\varphi[\\psi_1/p_1, ..., \\psi_n/p_n]\\) inductively:\n\nIf \\(\\varphi\\) is \\(p_i\\), \\(\\varphi[\\psi_1/p_1, ..., \\psi_n/p_n]\\) is \\(\\psi_i\\).\nIf \\(\\varphi\\) is \\(\\neg \\chi\\), \\(\\varphi[\\psi_1/p_1, ..., \\psi_n/p_m]\\) is \\(\\neg \\chi[\\psi_1/p_1, ..., \\psi_n/p_m]\\).\nIf \\(\\varphi\\) is \\((\\chi \\to \\rho)\\), then \\(\\varphi[\\psi_1/p_1, ..., \\psi_n/p_n]\\) is \\((\\chi[\\psi_1/p_1, ..., \\psi_n/p_n]\\to \\rho[\\psi_1/p_1, ..., \\psi_n/p_n])\\).\n\n\n\nWe are now in a position to define the set of axioms of the system:\n\n\n\n\n\n\nAxioms\n\n\n\nA well-formed formula \\(\\varphi\\) is an axiom if, and only if, it is a substitution instance of one of the well-formed formulas below: \\[\n\\begin{array}{lll}\nA1 & & p \\to (q \\to p)\\\\\nA2 & & (p \\to (q \\to r)) \\to ((p \\to q) \\to (p \\to r))\\\\\nA3 & & (\\neg p \\to \\neg q) \\to ((\\neg p \\to q) \\to p)\n\\end{array}\n\\]\n\n\nWe will use a single rule of inference, which we call Modus Ponens (MP). The rule in question will enable us to move from two formulas of the form \\(\\varphi\\) and \\((\\varphi \\to \\psi)\\) to the formula \\(\\psi\\).\n\n\n\n\n\n\nRule of Inference\n\n\n\n\\[\n\\begin{array}{lll}\nMP & & \\varphi, \\ (\\varphi \\to \\psi)/\\psi\\\\\n\\end{array}\n\\]\n\n\nWe now explain what is for a formula to be derivable from a set of formulas:\n\n\n\n\n\n\nDerivability\n\n\n\nA well-formed formula \\(\\varphi\\) is derivable from a set of well-formed formulas \\(\\Gamma\\), written \\(\\Gamma \\vdash \\varphi\\), if, and only if, there is a finite sequence of well-formed formulas \\((\\chi_1, \\dots , \\chi_n)\\) such that\n\n\\(\\chi_n = \\varphi\\)\nfor each \\(m \\leq n\\), either\n\n\\(\\chi_m\\) is an axiom, or\n\\(\\chi_m \\in \\Gamma\\), or\n\\(\\chi_k = (\\chi_l \\to \\chi_m)\\), for some \\(k, l &lt;m\\).\n\n\nSuch a finite sequence \\(( \\chi_1, ..., \\chi_n )\\) is called a derivation (or a proof) of \\(\\varphi\\) from \\(\\Gamma\\).\n\n\nSo, a formula appears in a derivation if, and only if, it is either an axiom or a premise or the output of an application of modus ponens to two earlier members of the sequence.\n\n\n\n\n\n\nTheorem\n\n\n\nA well-formed formula \\(\\varphi\\) is a theorem, written \\(\\vdash \\varphi\\), if, and only if, \\(\\emptyset \\vdash \\varphi\\).\nWe write \\(\\nvdash \\varphi\\) to indicate that \\(\\varphi\\) is not a theorem.\n\n\nHere is a simple example of a derivation:\n\n\n\n\n\n\nExample\n\n\n\n\\(\\vdash p \\to p\\) \\[\n\\begin{array}{llll}\n1 & & p \\to ((p \\to p) \\to p) & A1[p/p, (p \\to p)/q]\\\\\n2 & & (p \\to ((p \\to p) \\to p))\\to & \\\\\n  & &\n((p \\to (p \\to p)) \\to (p \\to p)) & A2[p/p, (p \\to p)/q, p/r]\\\\\n3 & & (p \\to (p \\to p)) \\to (p \\to p) & \\text{MP} \\ 1, 2\\\\\n4 & & p \\to (p \\to p) & A1[p/p, p/q]\\\\\n5 & & p \\to p & \\text{MP} \\ 3, 4\\\\\n\\end{array}\n\\]\n\n\nIt is simple to generalize this argument into a schematic derivation of \\(\\varphi \\to \\varphi\\) from no premises: \\[\n\\vdash \\varphi \\to \\varphi\n\\]\nWe will soon develop a library of subroutines, which will facilitate the discussion of the question of whether a given formula is derivable from a set of formulas.\n\n3.3.1 The Deduction Theorem\nWe will rely on a very general result. First, some notational conventions.\n\n\n\n\n\n\nNotation\n\n\n\nWe write \\(\\Gamma, \\varphi\\) to abbreviate: \\(\\Gamma \\cup \\{\\varphi\\}\\). And we will similarly write \\(\\varphi \\vdash \\psi\\) to abbreviate: \\(\\{\\varphi\\} \\vdash \\psi\\).\n\n\n\n\n\n\n\n\nThe Deduction Theorem\n\n\n\nGiven a set of formulas \\(\\Gamma\\) and formulas \\(\\varphi\\) and \\(\\psi\\), \\(\\Gamma, \\varphi \\vdash \\psi\\) if, and only if, \\(\\Gamma \\vdash \\varphi \\to \\psi\\).\n\n\nOne direction is simple:\n\nTheorem 3.1 Given a set of formulas \\(\\Gamma\\) and formulas \\(\\varphi\\) and \\(\\psi\\), if \\(\\Gamma \\vdash \\varphi \\to \\psi\\), then \\(\\Gamma, \\varphi \\vdash \\psi\\)\n\n\nTo obtain a derivation of \\(\\psi\\) from \\(\\Gamma, \\varphi\\), we may extend a derivation of \\(\\varphi \\to \\psi\\) from \\(\\Gamma\\) with two additional steps: \\(\\varphi\\), which being a member of \\(\\Gamma, \\varphi\\), is available as a premise, and \\(\\psi\\) which is the output of Modus Ponens when applied to \\(\\varphi \\to \\psi\\) and \\(\\varphi\\).\n\nThe other direction is the deduction theorem, which requires a more involved justification:\n\n\n\n\n\n\nTheorem\n\n\n\nGiven a set of formulas \\(\\Gamma\\) and formulas \\(\\varphi\\) and \\(\\psi\\), if \\(\\Gamma, \\varphi \\vdash \\psi\\), then \\(\\Gamma \\vdash \\varphi \\to \\psi\\).\n\n\n\nChoose a set of formulas \\(\\Gamma\\) and a formula \\(\\varphi\\). We will use a complete induction on \\(n\\) to prove that for every non-zero \\(n\\):\n\nif \\((\\chi_1, ..., \\chi_n)\\) is a derivation of \\(\\psi\\) from \\(\\Gamma, \\varphi\\), then \\(\\Gamma \\vdash \\varphi \\to \\psi\\).\n\nThat is, we argue that\n\nif that is true for every \\(m &lt; n\\), then it is true for \\(n\\) as well,\n\nSo, we begin with the assumption:\n\nfor every \\(m &lt; n\\), if \\((\\chi_1, ..., \\chi_m )\\) is a derivation of a formula \\(\\psi\\) from \\(\\Gamma, \\varphi\\), then \\(\\Gamma \\vdash \\varphi \\to \\psi\\)\n\nWe want to prove that\n\nif \\((\\chi_1, ..., \\chi_n)\\) is a derivation of a formula \\(\\psi\\) from \\(\\Gamma, \\varphi\\), then \\(\\Gamma \\vdash \\varphi \\to \\psi\\).\n\nConsider a derivation of \\(\\psi\\) from \\(\\Gamma, \\varphi\\) of the form: \\[\n( \\chi_1, ..., \\chi_{n})\n\\] That means that \\(\\chi_{n}= \\psi\\).\nThere are four cases to consider:\nCase 1. \\(\\psi\\) is a logical axiom.\nHere is a derivation of \\(\\varphi \\to \\psi\\) from \\(\\Gamma\\): \\[\n\\begin{array}{lll}\n1 & & \\psi \\to (\\varphi \\to \\psi) & A1[\\psi/p, \\varphi/q]\\\\\n2 & & \\psi & \\\\\n3 & & \\varphi \\to \\psi & \\text{MP} \\ 1, 2\\\\\n\\end{array}\n\\]\nCase 2. \\(\\psi \\in \\Gamma\\)\nHere is a similar derivation of \\(\\varphi \\to \\psi\\) from \\(\\Gamma\\): \\[\n\\begin{array}{lll}\n1 & & \\psi \\to (\\varphi \\to \\psi) & A1[\\psi/p, \\varphi/q]\\\\\n2 & & \\psi &  \\\\\n3 & & \\varphi \\to \\psi & \\text{MP} \\ 1, 2\\\\\n\\end{array}\n\\] Case 3. \\(\\psi = \\varphi\\)\nSince \\(\\vdash \\varphi \\to \\varphi\\), a derivation of \\(\\varphi \\to \\varphi\\) is a derivation of \\(\\varphi \\to \\psi\\) from \\(\\Gamma\\). Therefore \\(\\Gamma \\vdash \\varphi \\to \\psi\\).\nCase 4. \\(\\chi_k = (\\chi_l \\to \\psi)\\) for some \\(k, l &lt; n\\)\nThat means that \\((\\chi_l \\to \\psi)\\) and \\(\\chi_l\\) are each in the sequence, which means that there are derivations \\((\\chi_1 \\dots, \\chi_l \\to \\psi)\\) and \\((\\chi_1, \\dots, \\chi_l)\\) of each formula \\(\\chi_l \\to \\psi\\) and \\(\\chi_l\\) from \\(\\Gamma, \\varphi\\) of length \\(&lt; n\\).\nSince both derivations have length strictly less than \\(n\\), by inductive hypothesis, \\(\\Gamma \\vdash \\varphi \\to (\\chi_l \\to \\psi)\\) and \\(\\Gamma \\vdash \\varphi \\to \\chi_l\\).\nTo build a derivation of \\(\\varphi \\to \\psi\\) from \\(\\Gamma\\), we may concatenate derivations of \\(\\varphi \\to (\\chi_1 \\to \\psi)\\) and \\(\\varphi \\to \\chi_l\\), respectively, from \\(\\Gamma\\): \\[\n\\begin{array}{llll}\n& & ... & \\\\\n& & \\vdots & \\\\\nk & & \\varphi \\to  (\\chi_l \\to \\psi) & \\Gamma \\vdash  \\varphi \\to  (\\chi_l \\to \\psi) \\\\\n& & \\vdots & \\\\\nm & & \\varphi \\to  \\chi_l & \\Gamma \\vdash  \\varphi \\to  \\chi_l\\\\\n& & \\vdots & \\\\\nn& & ((\\varphi \\to (\\chi_1 \\to \\psi)) \\to  & A2[\\varphi/p,\\chi_l/q,\\psi/r]\\\\\n& & ((\\varphi \\to \\chi_l)\\to (\\varphi \\to \\psi)) & \\\\\nn+1& & (\\varphi \\to \\chi_l)\\to (\\varphi \\to \\psi) & \\text{MP} \\ k, n\\\\\nn+2 & & \\varphi \\to \\psi & \\text{MP} \\ m, n+1\\\\\n\\end{array}\n\\] We conclude that given \\(\\Gamma\\) and \\(\\varphi\\), if \\(( \\chi_1, ..., \\chi_n)\\) is a derivation of a formula \\(\\psi\\) from \\(\\Gamma, \\varphi\\), then \\(\\Gamma \\vdash \\varphi \\to \\psi\\).\n\nThe deduction theorem encodes a common method of proof in mathematics. To establish a conditional \\(\\varphi \\to \\psi\\) in a mathematical context, you may simply adjoin \\(\\varphi\\) to your assumptions \\(\\Gamma\\) and set out to derive \\(\\psi\\) from them. That entitles you to conclude that \\(\\varphi \\to \\psi\\) is a deductive consequence of the original assumptions.\nWe will now use of the Deduction Theorem to prove some facts, which will facilitate the use of the axiom system.\n\n\\(\\vdash (\\varphi \\to \\psi) \\to ((\\psi \\to \\chi)\\to (\\varphi \\to \\chi))\\)\n\n\nGiven the Deduction Theorem, it suffices to note: \\[\n\\{\\varphi \\to \\psi \\} \\vdash (\\psi \\to \\chi) \\to (\\varphi \\to \\chi).\n\\] But given the Deduction Theorem, this reduces to: \\[\n\\{ \\varphi \\to \\psi, \\psi \\to \\chi\\} \\vdash \\varphi \\to \\chi,\n\\] and \\[\n\\{\\varphi \\to \\psi, \\psi \\to \\chi, \\varphi\\} \\vdash \\chi.\n\\] But it is simple to provide a derivation of \\(\\chi\\) from \\(\\{\\varphi \\to \\psi, \\psi \\to \\chi, \\varphi\\}\\): \\[\n\\begin{array}{llll}\n1 & & \\varphi \\to \\psi & \\text{Premise} \\\\\n2 & & \\varphi &  \\text{Premise} \\\\\n3 & & \\psi & \\text{MP} \\ 1, 2 \\\\\n4 & & \\psi \\to \\chi & \\text{Premise} \\\\\n5 & & \\chi & MP \\ 3, 4\\\\\n\\end{array}\n\\]\n\nHere is another helfpul observation:\n\n\\(\\vdash \\varphi \\to \\neg \\neg \\varphi\\)\n\n\nWe exploit the last two observations to produce a simple derivation of \\(\\varphi \\to \\neg \\neg \\varphi\\): \\[\n\\begin{array}{llll}\n1 & & \\neg \\neg \\neg \\varphi \\to \\neg \\varphi & \\text{Lemma} \\ 3.3\\\\\n2 & & (\\neg \\neg \\neg \\varphi \\to \\neg \\varphi) \\to (\\varphi \\to \\neg \\neg \\varphi) & \\text{Lemma} \\ 3.2\\\\\n3 & & \\varphi \\to \\neg \\neg \\varphi & \\text{MP} \\ 1, 2\n\\end{array}\n\\]\n\n\n\\(\\vdash (\\varphi \\to \\psi) \\to (\\neg \\psi \\to \\neg \\varphi)\\)\n\n\nGiven the Deduction Theorem, it suffices to establish: \\[\n\\{\\varphi \\to \\psi \\} \\vdash \\neg \\psi \\to \\neg \\varphi,\n\\] and \\[\n\\{\\varphi \\to \\psi, \\neg \\psi\\} \\vdash \\neg \\varphi.\n\\] Here is a derivation of \\(\\neg \\varphi\\) from \\(\\{\\varphi \\to \\psi, \\neg \\psi\\}\\): \\[\n\\begin{array}{llll}\n1 & & \\varphi \\to \\psi &  \\\\\n2 & & \\psi \\to \\neg \\neg \\psi & \\text{Lemma} \\ 3.4\\\\\n3 & & \\neg \\neg \\varphi \\to \\varphi & \\text{Lemma} \\ 3.3\\\\\n4 & & (\\neg \\neg \\varphi \\to \\varphi) \\to ((\\varphi \\to \\psi) \\to (\\neg \\neg \\varphi \\to \\psi)) & \\text{Lemma} \\ 1 \\\\\n5 & & (\\varphi \\to \\psi) \\to (\\neg \\neg \\varphi \\to \\psi) & \\text{MP} \\ 3, 4 \\\\\n6 & & \\neg \\neg \\varphi \\to \\psi & \\text{MP} \\ 1, 4 \\\\\n7 & & (\\neg \\neg \\varphi \\to \\psi) \\to ((\\psi \\to \\neg \\neg \\psi) \\to (\\neg \\neg \\varphi \\to \\neg \\neg \\psi)) & \\text{Lemma} \\ 4.1 \\\\\n8 & & (\\psi \\to \\neg \\neg \\psi) \\to (\\neg \\neg \\varphi \\to \\neg \\neg \\psi) & \\text{MP} \\ 6, 7\\\\\n9 & & \\neg \\neg \\varphi \\to \\neg \\neg \\psi & \\text{MP} \\ 2, 8\\\\\n10 & & (\\neg \\neg \\varphi \\to \\neg \\neg \\psi) \\to (\\neg \\psi \\to \\neg \\varphi) & \\text{Lemma} \\ 3.2\\\\\n11 & & \\neg \\psi \\to \\neg \\varphi & \\text{MP} \\ 9, 10\n\\end{array}\n\\]\n\n\n\n\n\n\n\nExercise\n\n\n\nUse the observations above in order to justify: \\[\n\\vdash (\\varphi \\to \\neg \\varphi) \\to \\neg \\varphi\n\\]\n\n\n\n\\(\\vdash \\neg  \\varphi \\to (\\varphi \\to \\psi)\\)\n\n\nGiven the Deduction Theorem, it suffices to show: \\[\n\\{\\neg \\varphi, \\varphi \\}\\vdash \\psi\n\\]\nHere is an outline of a derivation of \\(\\psi\\) from \\(\\{\\neg \\varphi, \\varphi\\}\\): \\[\n\\begin{array}{llll}\n1 & & \\neg \\varphi \\to (\\neg \\psi \\to \\neg \\varphi) &  A1[\\neg \\varphi/p, \\neg \\psi/q] \\\\\n2 & &  \\neg \\varphi & \\text{Premise}\\\\\n3 & &  (\\neg \\psi \\to \\neg \\varphi) & \\text{MP 1, 2}\\\\\n4 & &  \\varphi \\to \\psi & 3, \\ \\text{Lemma 3.2}\\\\\n5 & & \\varphi  & \\text{Premise}\\\\\n6 & & \\psi  & \\text{MP 4, 5}\\\\\n\\end{array}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Basic Propositional Language</span>"
    ]
  },
  {
    "objectID": "comprop.html",
    "href": "comprop.html",
    "title": "4  Metatheory",
    "section": "",
    "text": "We want an axiom system to derive a formula \\(\\varphi\\) from a set of formulas \\(\\Gamma\\) only when \\(\\varphi\\) is a logical consequence of \\(\\Gamma\\). That is what would make the axiom system sound. On the other hand, we want to be able to derive a formula \\(\\varphi\\) from a set of formulas \\(\\Gamma\\) whenever \\(\\varphi\\) is a logical consequence of \\(\\Gamma\\). That is what would make the axiom system complete. We now set out to justify that the axiom system we have described is both sound and complete.\nHere is an important observation:\nWe have the toolkit we need in order to prove the completeness of the axiom system.\nWe follow an indirect route toward that conclusion.\nThat will suffice for our purposes. For given a set of formulas \\(\\Gamma\\) and a formula \\(\\varphi\\), if \\(\\Gamma \\nvdash \\varphi\\), then by proposition 3.6, \\(\\Gamma, \\neg \\varphi\\) is consistent. Given the link between consistency and satisfiability, we would infer that \\(\\Gamma, \\neg \\varphi\\) is satisfiable, whence \\(\\Gamma \\not \\models \\varphi\\).\nWe proceed in two steps:\n\\[\n\\begin{array}{clllc}\n\\Gamma  \\ \\text{consistent} & & & & \\Gamma \\ \\text{satisfiable}\\\\\n  \\Downarrow  & & & & \\Uparrow \\\\\n  \\exists \\Sigma \\ (\\Gamma  \\subseteq \\Sigma \\wedge  \\Sigma \\ \\text{maxcon}) & & \\Rightarrow & &   \\exists \\Sigma  \\ (\\Gamma  \\subseteq \\Sigma \\wedge  \\Sigma \\ \\text{satisfiable})\\\\\n\\end{array}\n\\]\nOne step enables us to move from the consistency of a set \\(\\Gamma\\) to the existence of a maximal consistent extension \\(\\Sigma\\) of that set.\nWe begin with an enumeration of the formulas of propositional logic: \\[\n\\varphi_0, \\varphi_1, \\cdots, \\varphi_n, \\cdots\n\\] Given \\(\\Gamma\\) be a consistent set of formulas, we build a maximal consistent superset \\(\\Sigma\\) by the recursion: \\[\n\\begin{array}{lll}\n\\Sigma_0 &  = &  \\Gamma \\\\\n\\Sigma_{n+1} & = & \\begin{cases} \\Sigma_n, \\varphi_n & \\text{if that set is consistent}\\\\ \\Sigma_n &  \\text{otherwise} \\end{cases}\n\\end{array}\n\\] We let \\[\n\\Sigma = \\bigcup_{n\\in \\mathbb{N}} \\Sigma_n.\n\\] We now argue that \\(\\Sigma\\) is a maximal consistent superset of \\(\\Gamma\\). We proceed in several steps.\nThis is because \\(\\Gamma = \\Sigma_0\\) and \\(\\Sigma_0 \\subseteq \\Sigma\\).\nA simple induction on \\(n\\) suffices:\nWe argue by induction on \\(n\\):\nIf \\(\\Delta\\) is a finite subset of \\(\\Sigma\\), then let \\(\\varphi_n\\) be the member of \\(\\Delta\\) of highest index. That is for all \\(m\\), if \\(\\varphi_m \\in \\Delta\\), then \\(m \\leq n\\). Notice that for each natural number \\(m\\), if \\(\\varphi_m \\in \\Sigma\\), then \\(\\varphi_m \\in \\Sigma_{m+1}\\). That is, a formula \\(\\varphi_m\\) is accepted into \\(\\Sigma\\) via \\(\\Sigma_{m+1}\\) if at all. So, it follows that \\(\\Delta \\subseteq \\Sigma_{n+1}\\) if \\(n\\) is the highest index of a formula in \\(\\Delta\\).\nIt follows from the above that every finite subset of \\(\\Sigma\\) is consistent. We now argue that \\(\\Sigma\\) is consistent as well.\nFor a reductio, suppose \\(\\Sigma \\vdash \\bot\\). That means that there is a finite derivation \\((\\chi_1, \\dots, \\chi_n)\\) of \\(\\bot\\) from \\(\\Sigma\\). That is therefore a derivation of \\(\\bot\\) from a finite subset of \\(\\Sigma\\), which would require a finite subset of \\(\\Sigma\\) to be inconsistent. That contradicts the observation that every finite subset of \\(\\Sigma\\) is consistent.\nA formula \\(\\varphi\\) will be assigned an index by the enumeration, which means \\(\\varphi = \\varphi_n\\). Now, if \\(\\Sigma, \\varphi_n\\) is consistent, then \\(\\Sigma_n, \\varphi_n\\) will be consistent as well. But that means that by construction of \\(\\Sigma\\), \\(\\varphi_n \\in \\Sigma_{n+1} \\subseteq \\Sigma\\). :::\nWe conclude that \\(\\Sigma\\) is a maximal consistent superset of \\(\\Gamma\\).\nGiven a maximal consistent set \\(\\Sigma\\), consider a valuation \\(V\\) based on an assignment \\(v\\) such that: \\[\n\\begin{array}{lll}\nv(p_n) = 1 & \\text{iff} & p_n \\in \\Sigma.\n\\end{array}\n\\] We use an induction on the complexity of \\(\\varphi\\) to establish:\n\\[\n\\begin{array}{lll}\nV(\\varphi) = 1 & \\text{iff} & \\varphi \\in \\Sigma.\n\\end{array}\n\\]\n- Base Case:\n\\[\n\\begin{array}{llll}\nV(p_n) = 1 & \\text{iff} & v(p_n) = 1 & \\\\\n   & \\text{iff} & p_n \\in \\Sigma. & \\text{definition of} \\ v\n\\end{array}\n\\]\n- Inductive Step for \\(\\neg\\):\n\\[\n\\begin{array}{llll}\nV(\\neg \\varphi) = 1 & \\text{iff} & V(\\varphi) = 0 & \\\\\n    & \\text{iff} & \\varphi \\notin \\Sigma & \\text{Inductive Hypothesis} \\\\\n     & \\text{iff} & \\neg \\varphi \\in \\Sigma & \\text{Proposition 3.7, 2} \\\\\n\\end{array}\n\\]\n- Inductive Step for \\(\\to\\):\n\\[\n\\begin{array}{llll}\nV(\\varphi \\to \\psi) = 1 & \\text{iff} & V(\\varphi) = 0 \\ \\text{or} \\ V(\\psi) =1 & \\\\\n    & \\text{iff} & \\varphi \\notin \\Sigma \\ \\text{or} \\ \\psi \\in \\Sigma& \\text{Inductive Hypothesis} \\\\\n     & \\text{iff} & \\varphi \\to \\psi \\in \\Sigma & \\text{Proposition 3.7, 3} \\\\\n\\end{array}\n\\]\nWe conclude that \\(V\\) verifies exactly those formulas in \\(\\Sigma\\). So, it follows that \\(\\Sigma\\) is satisfiable.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Metatheory</span>"
    ]
  },
  {
    "objectID": "comprop.html#footnotes",
    "href": "comprop.html#footnotes",
    "title": "4  Metatheory",
    "section": "",
    "text": "This is problem 3 in assignment 2.↩︎\nIf \\(\\Gamma \\vdash \\varphi\\) and \\(\\Gamma \\vdash \\neg \\varphi\\), then \\(\\Gamma \\vdash \\bot\\). This is because by lemma 3.6, \\(\\Gamma \\vdash \\neg \\varphi \\to (\\varphi \\to \\bot)\\).↩︎",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Metatheory</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "5  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Summary</span>"
    ]
  }
]